{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de l'IA détecteur de plagiat\n",
    "- avant d'exécuter ce notebook, il faut éxécuter le fichier unpack.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/4d/7hlj929n5wn5h8gy4lz060680000gn/T/ipykernel_27358/1452262204.py\", line 2, in <module>\n",
      "    from transformers import BertTokenizer, BertModel\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/transformers/utils/__init__.py\", line 27, in <module>\n",
      "    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/transformers/utils/chat_template_utils.py\", line 39, in <module>\n",
      "    from torch import Tensor\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/nassimnady/Documents/M2/S9/LLM/LLM_projet_plagiat/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par importer toutes les librairies nécessaires pour le transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# Chemins des dossiers\n",
    "original = \"TestData1/Original\"\n",
    "copie = \"TestData1/Copy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajouter expliations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé ensuite la fonction qui va générer les embeddings via BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bert(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[0, 1:-1, :].mean(dim=0).numpy()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliquer la fonction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On génère ensuite un embedding de tout le corpus de textes origniaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/source/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m corpus \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m corpus_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(original, filename), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/source/'"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "corpus_embeddings = []\n",
    "for filename in os.listdir(original):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(original, filename), 'r') as f:\n",
    "            texte_original = f.read()\n",
    "            corpus.append(texte_original)\n",
    "            corpus_embeddings.append(embed_bert(texte_original, tokenizer, model))\n",
    "\n",
    "corpus_embeddings = np.array(corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_plagiarism(text, tokenizer, model, index, corpus_embeddings, output_file=\"plagiat.txt\", threshold=0.8):\n",
    "    \n",
    "    # Calcul de l'embedding du texte à vérifier\n",
    "    text_embedding = embed_bert(text, tokenizer, model)\n",
    "    D, I = index.search(np.array([text_embedding]), k=5)  # Recherche des k voisins les plus proches\n",
    "\n",
    "    # Stocker les textes similaires\n",
    "    similar_texts = []\n",
    "\n",
    "    # Ouverture du fichier pour écrire les résultats\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        for i in range(len(I[0])):\n",
    "            # Calcul de la similarité cosinus\n",
    "            similarity = util.cos_sim(text_embedding, corpus_embeddings[I[0][i]])\n",
    "            if similarity >= threshold:\n",
    "                detected_text = corpus[I[0][i]]\n",
    "                similar_texts.append({\n",
    "                    'text': detected_text,\n",
    "                    'similarity': similarity.item()\n",
    "                })\n",
    "                # Écriture dans le fichier\n",
    "                file.write(f\"Plagiat détecté :\\n\")\n",
    "                file.write(f\"- Texte source : {detected_text}\\n\")\n",
    "                file.write(f\"- Texte Similaire : {similar_texts}\\n\")\n",
    "                file.write(f\"- Similarité : {similarity.item():.2f}\\n\\n\")\n",
    "\n",
    "    print(f\"Résultats de plagiat enregistrés dans {output_file}\")\n",
    "    return similar_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé maintenant l'index FAISS puis on parcours le dossier contenant les copies pour trouver les plagiats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n",
      "Résultats de plagiat enregistrés dans plagiat.txt\n"
     ]
    }
   ],
   "source": [
    "# Créer l'index FAISS\n",
    "index = faiss.IndexFlatL2(corpus_embeddings.shape[1])\n",
    "index.add(corpus_embeddings)\n",
    "\n",
    "# Vérifier le plagiat\n",
    "for filename in os.listdir(copie):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(copie, filename), 'r') as f:\n",
    "            texte_copie = f.read()\n",
    "            resultats = check_plagiarism(texte_copie, tokenizer, model, index, corpus_embeddings)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
